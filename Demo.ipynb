{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dependency libraries used for the RRG:\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import scipy as spy\n",
    "import itertools\n",
    "import copy\n",
    "from scipy.signal import argrelextrema\n",
    "from scipy.linalg import expm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HighOrderLaplician(A, Type, Order):\n",
    "    ## Input: \n",
    "    # A is the 1st-order adjacency matrix of the graph\n",
    "\n",
    "    # Type is a str that determines which type of high order Laplician representation to use\n",
    "    # Type='MOL': the function generates the multi-order Laplacian operator, which is \n",
    "    # Type='HOPL': the function generates the high-order path Laplacian operator proposed in our work\n",
    "\n",
    "    # Order is a number that determines which order of interactions to analyze\n",
    "\n",
    "    ## Output:\n",
    "    # L is the high order Laplician representation, which is the Multiorder Laplacian operator or the high-order path Laplacian\n",
    "    Num = A.shape[0]\n",
    "    # Stores the vertices\n",
    "    store = [0]* (Order+1)\n",
    "\n",
    "    # Degree of the vertices\n",
    "    # d = [deg for (_, deg) in G.degree()]\n",
    "    d = list(np.sum(A,axis=0))\n",
    "\n",
    "    Cliques = []\n",
    "    # Function to check if the given set of vertices\n",
    "    # in store array is a clique or not\n",
    "    def is_clique(b) :\n",
    "        # Run a loop for all the set of edges\n",
    "        # for the select vertex\n",
    "        for i in range(b) :\n",
    "            for j in range(i + 1, b) :\n",
    "                # If any edge is missing\n",
    "                if (A[store[i]][store[j]] == 0) :\n",
    "                    return False\n",
    "        return True\n",
    "\n",
    "    # Function to find all the cliques of size s\n",
    "    def findCliques(i, l, s) :    \n",
    "        # Check if any vertex from i+1 can be inserted as the l-th node in the simplex of size s\n",
    "        for j in range( i + 1, Num) :\n",
    "            # If the degree of the graph is sufficient\n",
    "            if (d[j] >= s - 1) :\n",
    "                # Add the vertex to store\n",
    "                store[l] = j\n",
    "                # If the graph is not a clique of size k\n",
    "                # then it cannot be a clique\n",
    "                # by adding another edge\n",
    "                if (is_clique(l + 1)) :\n",
    "                    # If the length of the clique is\n",
    "                    # still less than the desired size\n",
    "                    if (l < s-1) :\n",
    "                        # Recursion to add vertices\n",
    "                        findCliques(j, l + 1, s)\n",
    "                    # Size is met\n",
    "                    else :\n",
    "                        Cliques.append(store[:s])\n",
    "    findCliques(-1, 0, Order+1)\n",
    "\n",
    "    if len(Cliques)>0:\n",
    "        if Type=='MOL': # the multi-order Laplacian operator\n",
    "            HO_A = np.zeros((Num, Num))\n",
    "            for Simplex in Cliques:\n",
    "                for [i, j] in itertools.combinations(Simplex,2):\n",
    "                    HO_A[i,j] += 1\n",
    "            HO_A += HO_A.T\n",
    "            HO_D = sum(HO_A)\n",
    "            L = Order * np.diag(HO_D) - HO_A\n",
    "        elif Type=='HOPL': # the high-order path Laplacian operator\n",
    "            HO_A = np.zeros((Num, Num))\n",
    "            for Simplex in Cliques:\n",
    "                for [i, j] in itertools.combinations(Simplex,2):\n",
    "                    HO_A[i,j] += 1\n",
    "            HO_A += HO_A.T\n",
    "            HO_D = sum(HO_A)\n",
    "            L = np.diag(HO_D) - HO_A   \n",
    "    else:\n",
    "        L=np.zeros((Num,Num))\n",
    "    return L\n",
    "\n",
    "def NetworkInfo(L):\n",
    "    ## Input: \n",
    "    # L is the high order Laplician representation, which can be the Multiorder Laplacian operator or the high-order path Laplacian\n",
    "\n",
    "    ## Output:\n",
    "    # Sub_Ls the list of the sub-Laplician-matrices associated with all connected components from L\n",
    "    # Sub_NodeIDs is the list of sub-node-indice associated with all connected components from L\n",
    "    G=nx.from_numpy_array(np.abs(L)-np.diag(np.diag(L)))\n",
    "    Sub_Ls=[L[list(SG),:][:,list(SG)] for SG in nx.connected_components(G)] \n",
    "    Sub_NodeIDs=[list(SG) for SG in nx.connected_components(G)]\n",
    "    return Sub_Ls, Sub_NodeIDs\n",
    "\n",
    "def NetworkUnion(Sub_Ls):\n",
    "    L=np.ones((1,1))\n",
    "    for SL in Sub_Ls:\n",
    "        L=spy.linalg.block_diag(L,SL)\n",
    "    L=L[1:,1:]\n",
    "    return L\n",
    "\n",
    "def SRG_Flow(G,q,p,L_Type,IterNum):\n",
    "    A=nx.adjacency_matrix(G).toarray()       \n",
    "    L=HighOrderLaplician(A, L_Type, Order=q)\n",
    "    L0=HighOrderLaplician(A, L_Type, Order=p)\n",
    "    L_List,L0_List,C_List,Tracked_Alignment=SRG_Function(L,L0,q,IterNum)\n",
    "    return L_List,L0_List,C_List,Tracked_Alignment\n",
    "\n",
    "    \n",
    "def SRG_Function(L,L0,q,IterNum):\n",
    "    ## Input: \n",
    "    # L is the initial guiding high order Laplician representation, which can be the Multiorder Laplacian operator or the high-order path Laplacian\n",
    "    # L0 is the initial guided high order Laplician representation, which can be the Multiorder Laplacian operator or the high-order path Laplacian\n",
    "\n",
    "    ## Output:\n",
    "    # L_List is the list of the guiding q-order Laplacian over renormalization steps\n",
    "    # L0_List is the list of the guided p-order Laplacian over renormalization steps\n",
    "    # C_List is the list of specific heat vector calculated by the initial q - order Laplacian L_List[0] and a range of time scale\n",
    "    # Tracked_Alignment is the indexes of the initial units aggregated into each macro-unit of all connected clusters after every iteration of the SRG\n",
    "    Iter=1\n",
    "    Init_Sub_Ls,_=NetworkInfo(L)\n",
    "    L_List=[L]\n",
    "    L0_List=[L0]\n",
    "    tau_Vec=np.zeros(len(Init_Sub_Ls))\n",
    "    C_List=[]\n",
    "    for ID in range(len(Init_Sub_Ls)):\n",
    "        if np.size(Init_Sub_Ls[ID],0)>1:\n",
    "            tau,CVector=TauSelection(Init_Sub_Ls[ID])\n",
    "            tau=tau/((q+1)/2)\n",
    "            tau_Vec[ID]=tau\n",
    "            C_List.append(CVector)\n",
    "    All_Alignment=[]\n",
    "    while Iter<IterNum:\n",
    "        Current_L=L_List[Iter-1]\n",
    "        Current_L0=L0_List[Iter-1]\n",
    "        Current_G0=nx.from_numpy_array(np.abs(Current_L0)-np.diag(np.diag(Current_L0)))\n",
    "        Sub_Ls, Sub_NodeIDs=NetworkInfo(Current_L)\n",
    "        NewSub_Ls=[]\n",
    "        ClusterNodeAlignment=[]\n",
    "        for SLID in range(len(Sub_Ls)):\n",
    "            SL=Sub_Ls[SLID]\n",
    "            SNodeID = Sub_NodeIDs[SLID]\n",
    "            if np.size(SL,0)==1:\n",
    "                NodeAlignment=[]\n",
    "                NewSub_Ls.append(SL)\n",
    "                NodeAlignment.append([SNodeID[0],SNodeID])\n",
    "            else:\n",
    "                NodeAlignment=[]\n",
    "                Evals, _ = np.linalg.eig(SL)\n",
    "                tau=tau_Vec[SLID]\n",
    "                Eval_idx = np.where(np.real(Evals)>1/tau)[0]\n",
    "\n",
    "                Rho = expm(-tau*SL)/np.trace(expm(-tau*SL))\n",
    "                rho_Evals, rho_Evecs = np.linalg.eig(Rho)\n",
    "                rho = np.zeros((Rho.shape[0],Rho.shape[1]))\n",
    "                for ID in Eval_idx:\n",
    "                    Evec = rho_Evecs[:,ID].reshape(-1,1)\n",
    "                    rho += np.real(rho_Evals[ID]*np.matmul(Evec,Evec.T))\n",
    "                adj1 = np.zeros((rho.shape[0],rho.shape[1]))\n",
    "                for i in range(SL.shape[0]):\n",
    "                    for j in range(SL.shape[1]):\n",
    "                        if i==j:\n",
    "                            continue\n",
    "                        elif ((rho[i][j]>=rho[j][j]) or (rho[i][j]>=rho[i][i])):\n",
    "                            adj1[i][j]=1\n",
    "                            adj1[j][i]=1\n",
    "                RefG = nx.from_numpy_array(adj1) # reference graph\n",
    "                # delete false edges not in subgraph of SL\n",
    "                Current_SG=nx.from_numpy_array(np.abs(SL)-np.diag(np.diag(SL)))\n",
    "                Potential_Clusters=[list(c) for c in list(nx.connected_components(RefG))]\n",
    "                Edge_To_Remove=[]\n",
    "                for ID1 in range(len(Potential_Clusters)):\n",
    "                    Unit_list=Potential_Clusters[ID1]\n",
    "                    if len(Unit_list)>1:\n",
    "                        H = nx.induced_subgraph(Current_SG,Unit_list)\n",
    "                        Potential_H = nx.induced_subgraph(RefG,Unit_list)\n",
    "                        Wrong_Edge=list(set(list(Potential_H.edges))-set(list(H.edges)))\n",
    "                        Edge_To_Remove.extend(Wrong_Edge)\n",
    "                for Wrong_Edge in Edge_To_Remove:\n",
    "                    RefG.remove_edge(*Wrong_Edge)\n",
    "                Clusters=[list(c) for c in list(nx.connected_components(RefG))]\n",
    "                # contracting SG nodes\n",
    "                for Nodes in Clusters:\n",
    "                    Node1 = Nodes[0]\n",
    "                    for node in Nodes[1:]:\n",
    "                        Current_SG = nx.contracted_nodes(Current_SG, Node1, node, self_loops=False)\n",
    "                mapping = {old_label:new_label for new_label, old_label in enumerate(Current_SG.nodes())}\n",
    "                Current_SG = nx.relabel_nodes(Current_SG, mapping)\n",
    "                New_SA = nx.adjacency_matrix(Current_SG).toarray()\n",
    "                # contracting G0 nodes\n",
    "                for Nodes in Clusters:\n",
    "                    SNodes = [SNodeID[node] for node in Nodes]\n",
    "                    Node1 = SNodes[0]\n",
    "                    NodeAlignment.append([Node1, SNodes])\n",
    "                    for node in SNodes[1:]:\n",
    "                        Current_G0 = nx.contracted_nodes(Current_G0, Node1, node, self_loops=False)\n",
    "                    \n",
    "                New_SL = np.diag(np.sum(New_SA,axis=0)) - New_SA\n",
    "                NewSub_Ls.append(New_SL)\n",
    "            ClusterNodeAlignment.append(NodeAlignment)\n",
    "        All_Alignment.append(ClusterNodeAlignment)\n",
    "\n",
    "        mapping = {old_label:new_label for new_label, old_label in enumerate(Current_G0.nodes())}\n",
    "        Current_G0 = nx.relabel_nodes(Current_G0, mapping)\n",
    "        New_A0 = nx.adjacency_matrix(Current_G0).toarray()\n",
    "        New_L0 = np.diag(np.sum(New_A0,axis=0)) - New_A0\n",
    "        New_L=NetworkUnion(NewSub_Ls)\n",
    "        print('Nn:', New_L.shape[0])\n",
    "\n",
    "        L_List.append(New_L)\n",
    "        L0_List.append(New_L0)\n",
    "        Iter=Iter+1\n",
    "    Tracked_Alignment=TrackingUnitID(All_Alignment,L.shape[0])\n",
    "    return L_List,L0_List,C_List,Tracked_Alignment\n",
    "\n",
    "def TauSelection(L):\n",
    "    ## Input: \n",
    "    # L is the initial high order Laplician representation, which can be the Multiorder Laplacian operator or the high-order path Laplacian\n",
    "\n",
    "    ## Output:\n",
    "    # tau is the ideal constant that determines the time scale\n",
    "    TauVec=np.logspace(-2, 2, 200) # reconmennd tau in (1e-2,1e0) for q>1\n",
    "    MLambdaVector=np.zeros_like(TauVec)\n",
    "    for ID in range(len(TauVec)):\n",
    "        Poss_tau=TauVec[ID]\n",
    "        MatrixExp=spy.linalg.expm(-Poss_tau*L)\n",
    "        Rho=MatrixExp/np.trace(MatrixExp)\n",
    "        MLambdaVector[ID]=np.trace(L @ Rho)\n",
    "    CVector=-np.power(TauVec[1:],2)*np.diff(MLambdaVector)/np.diff(TauVec)\n",
    "    CVector = CVector[np.where(~np.isnan(CVector))[0]]\n",
    "    TauVec = TauVec[np.where(~np.isnan(CVector))[0]]\n",
    "\n",
    "    potential_localmax_id = argrelextrema(CVector,np.greater)[0]\n",
    "    true_localmax_id = potential_localmax_id[np.where(CVector[potential_localmax_id]>0.5*np.max(CVector))[0]]\n",
    "    tau=TauVec[true_localmax_id[0]]\n",
    "\n",
    "    dCVector=np.diff(CVector)/np.diff(TauVec)\n",
    "    plateau_idx = np.where((np.abs(dCVector)<5e-2)&(TauVec[1:]>=tau))[0]\n",
    "    plateau_idx = [i for i in plateau_idx if i+1 in plateau_idx] # find consecutive index as true plateau\n",
    "    if len(plateau_idx)>50 and (CVector[plateau_idx]>0.1*np.max(CVector)).all():\n",
    "        tau = TauVec[plateau_idx[0]]\n",
    "    print(['our method: tau is ',tau,'!!'])\n",
    "    return tau,CVector\n",
    "\n",
    "def TrackingUnitID(All_Alignment,UnitNum):\n",
    "    # convert nodeID within an iteration (All_Alignment) to global nodeID (Tracked_Alignment)\n",
    "    Tracked_Alignment=copy.deepcopy(All_Alignment)\n",
    "    UnitIDVec=list(range(UnitNum))\n",
    "    for IterID in range(len(All_Alignment)):\n",
    "        if IterID>0:\n",
    "            for ClusterID in range(len(All_Alignment[IterID])):\n",
    "                for CoarseID in range(len(All_Alignment[IterID][ClusterID])):\n",
    "                    NodesToTrack=All_Alignment[IterID][ClusterID][CoarseID][1]\n",
    "                    for IDT in range(len(NodesToTrack)):\n",
    "                        TrackedID=UnitIDVec[NodesToTrack[IDT]]\n",
    "                        Tracked_Alignment[IterID][ClusterID][CoarseID][1][IDT]=TrackedID\n",
    "                    Tracked_Alignment[IterID][ClusterID][CoarseID][0]=Tracked_Alignment[IterID][ClusterID][CoarseID][1][0]\n",
    "        # delete Coarsed node\n",
    "        NodetoDelete=[]\n",
    "        for ClusterID in range(len(Tracked_Alignment[IterID])):\n",
    "            for CoarseID in range(len(Tracked_Alignment[IterID][ClusterID])):\n",
    "                Nodes=Tracked_Alignment[IterID][ClusterID][CoarseID][1][1:]\n",
    "                NodetoDelete.extend(Nodes)\n",
    "\n",
    "        for IDD in NodetoDelete:\n",
    "            UnitIDVec.remove(IDD)\n",
    "\n",
    "    return Tracked_Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "G=nx.random_graphs.barabasi_albert_graph(1000,4) # Generate a a random BA network with 1000 units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiorder Laplacian operator\n",
    "L_List,L0_List,C_List,Tracked_Alignment=SRG_Flow(G,q=1,p=1,L_Type='MOL',IterNum=5) # Run a SRG for 5 iterations, which renormalize the system on the 1-order based on the 1-order interactions\n",
    "\n",
    "L_List,L0_List,C_List,Tracked_Alignment=SRG_Flow(G,q=2,p=1,L_Type='MOL',IterNum=5) # Run a SRG for 5 iterations, which renormalize the system on the 1-order based on the 2-order interactions\n",
    "\n",
    "L_List,L0_List,C_List,Tracked_Alignment=SRG_Flow(G,q=3,p=1,L_Type='MOL',IterNum=5) # Run a SRG for 5 iterations, which renormalize the system on the 1-order based on the 3-order interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# High-order path Laplacian\n",
    "L_List,L0_List,C_List,Tracked_Alignment=SRG_Flow(G,q=1,p=1,L_Type='HOPL',IterNum=5) # Run a SRG for 5 iterations, which renormalize the system on the 1-order based on the 1-order interactions\n",
    "\n",
    "L_List,L0_List,C_List,Tracked_Alignment=SRG_Flow(G,q=2,p=1,L_Type='HOPL',IterNum=5) # Run a SRG for 5 iterations, which renormalize the system on the 1-order based on the 2-order interactions\n",
    "\n",
    "L_List,L0_List,C_List,Tracked_Alignment=SRG_Flow(G,q=3,p=1,L_Type='HOPL',IterNum=5) # Run a SRG for 5 iterations, which renormalize the system on the 1-order based on the 3-order interactions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dolo2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
